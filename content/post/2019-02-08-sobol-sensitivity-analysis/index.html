---
title: 'Sobol Sensitivity Analysis for Pharmacokinetic Model'
summary: Using mrgsolve package and its approach to conduct Sobol sensitivity analysis in pharmacokinetic modeling
authors:
- admin
date: "2019-02-08"
output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
projects: [PBPK]
categories: [sensitivity]
tags: [sensitivity, pharmacokinetics, Sobol, mrgsolve]

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight  
# image:
#  placement: 2
#  preview_only: true
#  focal_point: 'TopRight'
#  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/CpkOjOcXdUY)'

---


<div id="TOC">
<ul>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#reproducible-analysis">Reproducible analysis</a><ul>
<li><a href="#the-sunitinib-pk-model">The sunitinib PK model</a></li>
<li><a href="#sunitinib-dosing">Sunitinib dosing</a></li>
<li><a href="#a-bunch-of-helper-functions">A bunch of helper functions</a></li>
<li><a href="#sobol-sensitivity-analysis">Sobol sensitivity analysis</a></li>
<li><a href="#results">Results</a></li>
</ul></li>
<li><a href="#methods-and-defined-functions">Methods and defined functions</a><ul>
<li><a href="#log-uniform-quasi-monte-carlo-sampling">Log-uniform &amp; quasi-Monte Carlo sampling</a></li>
<li><a href="#convergence-analysis">Convergence analysis</a></li>
</ul></li>
<li><a href="#results-1">Results</a><ul>
<li><a href="#sobol-sensitivity-analysis-1">Sobol sensitivity analysis</a></li>
<li><a href="#convergence-assessment">Convergence assessment</a></li>
</ul></li>
<li><a href="#take-away">Take away</a></li>
<li><a href="#session-info">Session info</a></li>
</ul>
</div>

<p>{{% alert note %}}
<strong><strong>The post was updated on 2019-12-31 under Windows 10 x64.</strong></strong>
{{% /alert %}}</p>
<p>I find a great <a href="https://github.com/mrgsolve/gallery/blob/master/application/sobol.md">example</a> of performing Sobol sensitivity analysis within pharmacokinetic modeling through <a href="https://mrgsolve.github.io/">mrgsolve</a> and <a href="https://dpastoor.github.io/PKPDmisc/">PKPDmisc</a>. I didn’t have any experience to use these packages in my study. But this is a good opportunity to understand how they work since I have prior knowledge in the sensitivity analysis. Last year, I was lucky to have a chance to participate in <a href="https://ec.europa.eu/jrc/en/event/training-course/samo-2018">the 10th summer school on Sensitivity Analysis of Model Output</a> (SAMO 2018).<br />
Here I want to apply some techniques that I learned in this SAMO summer school, and it might be helpful to apply Sobol sensitivity analysis in pharmacokinetic modeling. Maybe in the future, I can integrate this approach in <a href="https://nanhung.rbind.io/pksensi/index.html">pksensi</a>.</p>
<div id="prerequisites" class="section level2">
<h2>Prerequisites</h2>
<p>The list of R packages should be installed first to do the following testing. The related functions are also listed behind the package.</p>
<pre class="r"><code>library(tidyverse) 
library(mrgsolve) # mrgsim_ei
library(PKPDmisc) # auc_partial 
library(sensitivity) # sobol2007
library(randtoolbox) # sobol
library(reshape2) # melt
library(LSD) # heatscatter</code></pre>
<p>For Windows OS, some build tools need to pre-install, such as Rtools. Also, be sure to assign the right PATH to Rtools.</p>
<pre class="r"><code>Sys.setenv(PATH = paste(&quot;c:\\Rtools\\bin&quot;, Sys.getenv(&quot;PATH&quot;), sep=&quot;;&quot;))
Sys.setenv(PATH = paste(&quot;c:\\Rtools\\mingw_64\\bin&quot;, Sys.getenv(&quot;PATH&quot;), sep=&quot;;&quot;))</code></pre>
<pre class="r"><code>pkgbuild::check_build_tools(debug=TRUE)</code></pre>
<hr />
</div>
<div id="reproducible-analysis" class="section level1">
<h1>Reproducible analysis</h1>
<p>This section is used to reproduce the result in previous post.</p>
<div id="the-sunitinib-pk-model" class="section level2">
<h2>The sunitinib PK model</h2>
<pre class="r"><code>mod &lt;- mread(&quot;sunit&quot;, &quot;models&quot;) %&gt;% 
  update(end = 24, delta = 1) %&gt;% zero_re</code></pre>
<pre class="r"><code>see(mod)</code></pre>
</div>
<div id="sunitinib-dosing" class="section level2">
<h2>Sunitinib dosing</h2>
<pre class="r"><code>sunev &lt;- function(amt = 50,...) ev(amt = amt, ...)</code></pre>
</div>
<div id="a-bunch-of-helper-functions" class="section level2">
<h2>A bunch of helper functions</h2>
<pre class="r"><code>gen_samples&lt;- function(n, l, which = names(l), factor = c(0.01,100)) {
  vars &lt;- select_vars(names(l), !!(enquo(which)))
  l &lt;- as.list(l)[vars]
  l &lt;- lapply(l, function(x) {
    x*factor  
  })
  n &lt;- length(l)*n*2
  df &lt;- as.data.frame(l)
  len &lt;- length(df)
  X &lt;- matrix(ncol=len, nrow=n)
  colnames(X) &lt;- names(df)
  Y &lt;- X
  for(i in seq(len)){
    r &lt;- runif(n, df[1,i], df[2,i])
    X[,i] &lt;- r
    r &lt;- runif(n, df[1,i], df[2,i])
    Y[,i] &lt;- r
  }
  return(list(x1 = as.data.frame(X), x2 = as.data.frame(Y)))
} </code></pre>
<pre class="r"><code>sim_chunk &lt;- function(mod, x) {
  mrgsim_ei(x = mod, ev = sunev(), 
            idata = x, obsonly = TRUE) %&gt;% 
    as_data_frame
}</code></pre>
<pre class="r"><code>batch_run &lt;- function(x) {
  out &lt;- sim_chunk(mod,x)
  out &lt;- group_by(out,ID) %&gt;% 
    summarise(AUC = auc_partial(time,CP))
  return(out$AUC)
}</code></pre>
</div>
<div id="sobol-sensitivity-analysis" class="section level2">
<h2>Sobol sensitivity analysis</h2>
<p>The sampling method is based on this <a href="https://github.com/metrumresearchgroup/pbpk-qsp-mrgsolve/blob/master/docs/global_sensitivity_analysis.md">example</a>. Therefore I can fully reproduce the same output.</p>
<pre class="r"><code>set.seed(88771)
samp &lt;- gen_samples(6000, param(mod), TVCL:TVVP)
head(samp$x1)</code></pre>
<pre class="r"><code>x &lt;- sobol2007(batch_run, X1=samp$x1, X2=samp$x2, nboot=100)</code></pre>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<pre class="r"><code>plot(x)</code></pre>
<p>The result shows that only TVCL and TVVC can significantly dominate the output result. Also, it’s difficult to determine the influence of TVKA, TVQ, and TVVP.</p>
<pre class="r"><code>x</code></pre>
</div>
</div>
<div id="methods-and-defined-functions" class="section level1">
<h1>Methods and defined functions</h1>
<div id="log-uniform-quasi-monte-carlo-sampling" class="section level2">
<h2>Log-uniform &amp; quasi-Monte Carlo sampling</h2>
<p>Based on the <code>gen_samples()</code> above, I further create two functions. The first one sample the parameters under the log-transformed parameter range. The main reason to develop this function is that the setting range of model parameters are extremely large in this example. The original example generated uniform samples from a 100 fold decrease to 100 fold increase based on the nominal parameter value. It might cause an unexpected sampling bias. Therefore, the new function aims to solve this problem.</p>
<p>Let’s call this function as <code>gen_samples_1()</code>.</p>
<pre class="r"><code>gen_samples_1 &lt;- function(n, l, which = names(l), factor = c(0.01,100)) {
  vars &lt;- select_vars(names(l), !!(enquo(which)))
  l &lt;- as.list(l)[vars]
  l &lt;- lapply(l, function(x) {x*factor})
  xx &lt;- log(factor, 10)[2] - log(factor, 10)[1]
  len &lt;- length(vars)
  X &lt;- matrix(runif(len * length(l)*n*2), ncol = len)
  Y &lt;- matrix(runif(len * length(l)*n*2), ncol = len)
  for(i in seq(len)){
    X[,i] &lt;- l[[i]][[1]] * 10^(X[,i] * xx)
    Y[,i] &lt;- l[[i]][[1]] * 10^(Y[,i] * xx)
    colnames(X) &lt;- colnames(Y) &lt;- vars 
  }
  return(list(x1 = as.data.frame(X), x2 = as.data.frame(Y)))
}</code></pre>
<p>Instead of the log-transformed parameter sampling, I further used <a href="https://en.wikipedia.org/wiki/Quasi-Monte_Carlo_method">quasi-Monte Carlo method</a> (QMC) in the second new function. Generally, this method can create a relative uniformly parameter condition than the random method. Let’s call this function as <code>gen_samples_2()</code>.</p>
<pre class="r"><code>gen_samples_2 &lt;- function(n, l, which = names(l), factor = c(0.01,100)) {
  vars &lt;- select_vars(names(l), !!(enquo(which)))
  l &lt;- as.list(l)[vars]
  l &lt;- lapply(l, function(x) {x*factor})
  xx &lt;- log(factor, 10)[2] - log(factor, 10)[1]
  len &lt;- length(vars)
  
  X &lt;- sobol(n = length(l)*n*2, dim = 5)
  Y &lt;- sobol(n = length(l)*n*2, dim = 5, seed = 2345, scrambling = 3)
  
  for(i in seq(len)){
    X[,i] &lt;- l[[i]][[1]] * 10^(X[,i] * xx)
    Y[,i] &lt;- l[[i]][[1]] * 10^(Y[,i] * xx)
    colnames(X) &lt;- colnames(Y) &lt;- vars 
  }
  return(list(x1 = as.data.frame(X), x2 = as.data.frame(Y)))
}</code></pre>
</div>
<div id="convergence-analysis" class="section level2">
<h2>Convergence analysis</h2>
<p>This is one of the critical steps in the sensitivity analysis. More details can be found in my published paper in <a href="https://www.frontiersin.org/articles/10.3389/fphar.2018.00588/full">Frontiers in Pharmacology</a>. Here I create a function called <code>sample_converge()</code>, which can generate the convergence index based on the values of the given sample number. The drawback of this function is time-consuming. Because it estimates the convergence index at each sample number and each defined sampling function.</p>
<pre class="r"><code>sample_converge &lt;- function(n, l, which = names(l)){
  vars &lt;- select_vars(names(l), !!(enquo(which)))
  m &lt;- matrix(NA, length(n), length(vars))
  colnames(m) &lt;- vars
  rownames(m) &lt;- n
  m2 &lt;- m1 &lt;- m
  for (i in seq(length(n))){
    samp &lt;- gen_samples(n[i], l, names(vars))
    samp1 &lt;- gen_samples_1(n[i], l, names(vars))
    samp2 &lt;- gen_samples_2(n[i], l, names(vars))
    x &lt;- sobol2007(batch_run, X1=samp$x1, X2=samp$x2, nboot=100)
    x1 &lt;- sobol2007(batch_run, X1=samp1$x1, X2=samp1$x2, nboot=100)
    x2 &lt;- sobol2007(batch_run, X1=samp2$x1, X2=samp2$x2, nboot=100)
    m[i,] &lt;- x$T[,&quot;max. c.i.&quot;] - x$T[,&quot;min. c.i.&quot;]
    m1[i,] &lt;- x1$T[,&quot;max. c.i.&quot;] - x1$T[,&quot;min. c.i.&quot;]
    m2[i,] &lt;- x2$T[,&quot;max. c.i.&quot;] - x2$T[,&quot;min. c.i.&quot;]
  } 
  X &lt;- list(MC = m, log_MC = m1, log_QMC = m2)
  m %&gt;% melt()
  
  return(X)
}</code></pre>
</div>
</div>
<div id="results-1" class="section level1">
<h1>Results</h1>
<p>The first step in this section is using three defined functions to generate the testing parameter sets. The sampling number is 1000 for 5 parameters of TVCL, TVVC, TVKA, TVQ, and TVVP.</p>
<pre class="r"><code>set.seed(88771) 
samp &lt;- gen_samples(1000, param(mod), TVCL:TVVP)
set.seed(88771)
samp1 &lt;- gen_samples_1(1000, param(mod), TVCL:TVVP)
set.seed(88771)
samp2 &lt;- gen_samples_2(1000, param(mod), TVCL:TVVP)</code></pre>
<pre class="r"><code>head(samp$x1)
head(samp1$x1)
head(samp2$x1)</code></pre>
<p>We can check the range of TVCL.</p>
<pre class="r"><code>i &lt;- &quot;TVCL&quot;</code></pre>
<pre class="r"><code>range(samp$x1[,i])
range(samp1$x1[,i])
range(samp2$x1[,i])</code></pre>
<p>The probability distributions of TVCL look like this.</p>
<pre class="r"><code>par(mfrow = c(3,2), mar = c(2,2,1,1))
samp$x1[,i] %&gt;% density() %&gt;% plot(main = &quot;MC&quot;)
samp1$x1[,i] %&gt;% density() %&gt;% plot(main = &quot;Log MC&quot;)
samp1$x1[,i] %&gt;% log(10) %&gt;% density() %&gt;% plot(main = &quot;Log MC&quot;)
samp2$x1[,i] %&gt;% log(10) %&gt;% density() %&gt;% plot(main = &quot;Log QMC&quot;)
samp$x1[,i] %&gt;% log(10) %&gt;% density() %&gt;% plot(main = &quot;MC&quot;)</code></pre>
<p>Although the sampling ranges are nearly the same, we can easily understand how different sampling methods that cause the difference of parameter sampling result.</p>
<pre class="r"><code>j &lt;- &quot;TVKA&quot;
par(mfrow = c(3,2), mar = c(2,2,4,1))
heatscatter(samp$x1[,i], samp$x1[,j], add.contour=T, 
            nlevels=3, xlab = i, ylab = j, main = &quot;MC&quot;)
heatscatter(samp1$x1[,i], samp1$x1[,j], add.contour=T,
            nlevels=3, xlab = i, ylab = j, main = &quot;Log MC&quot;)
heatscatter(log(samp1$x1[,i]), log(samp1$x1[,j]), add.contour=T,
            nlevels=3, xlab = i, ylab = j, main = &quot;Log MC&quot;)
heatscatter(log(samp2$x1[,i]), log(samp2$x1[,j]), add.contour=T,
            nlevels=3, xlab = i, ylab = j, main = &quot;Log QMC&quot;)
heatscatter(log(samp$x1[,i]), log(samp$x1[,j]), add.contour=T,
            nlevels=3, xlab = i, ylab = j, main = &quot;MC&quot;)</code></pre>
<p>Here, we can find the devil in detail. The uniform sampling in the parameter range without log-transformed ignores the lowest range of value that might cause bias in sampling.</p>
<div id="sobol-sensitivity-analysis-1" class="section level2">
<h2>Sobol sensitivity analysis</h2>
<p>Now, let’s run <code>Sobol2007()</code> with sampling parameter sets that were generated above</p>
<pre class="r"><code>x &lt;- sobol2007(batch_run, X1=samp$x1, X2=samp$x2, nboot=100)
x1 &lt;- sobol2007(batch_run, X1=samp1$x1, X2=samp1$x2, nboot=100)
x2 &lt;- sobol2007(batch_run, X1=samp2$x1, X2=samp2$x2, nboot=100)</code></pre>
<p>Print result</p>
<pre class="r"><code>x
x1
x2</code></pre>
<p>Plot</p>
<pre class="r"><code>par(mfrow = c(2,2), mar = c(2,2,3,1))
plot(x, main = &quot;MC&quot;)
plot(x1, main = &quot;Log MC&quot;)
plot(x2, main = &quot;Log QMC&quot;)</code></pre>
<p>Same as above, we can find that only TVCL and TVVC have an obvious influence on the model output in the previous sampling method. However, the proposed methods can easily rank the importance of parameters in this case.</p>
<p>The results of the parameter vs. model output look like this.</p>
<pre class="r"><code>par(mfrow = c(3,2), mar = c(2,2,4,1))
for (i in 1:5){
  heatscatter(log(x$X[,i]), log(x$y), xlab = &quot;&quot;, ylab = &quot;&quot;, main = names(x$X)[i])
}</code></pre>
<p>This is the result of sampling in the log-transformed parameter range.</p>
<pre class="r"><code>par(mfrow = c(3,2), mar = c(2,2,4,1))
for (i in 1:5){
  heatscatter(log(x1$X[,i]), log(x1$y), xlab = &quot;&quot;, ylab = &quot;&quot;, main = names(x1$X)[i])
}</code></pre>
<p>It’s an efficient way to see the relationship between parameter value and model output. The high impact parameter has a relatively concentrated contour than other parameters.</p>
</div>
<div id="convergence-assessment" class="section level2">
<h2>Convergence assessment</h2>
<p>The convergence index can simply calculate through the 95% CI of sensitivity index that is estimated from bootstrapping in the Sobol method. Here is the result of the convergence index under the sample number of 1000 from the above section.</p>
<pre class="r"><code>x$T[,&quot;max. c.i.&quot;] - x$T[,&quot;min. c.i.&quot;]
x1$T[,&quot;max. c.i.&quot;] - x1$T[,&quot;min. c.i.&quot;]
x2$T[,&quot;max. c.i.&quot;] - x2$T[,&quot;min. c.i.&quot;]</code></pre>
<p>In this part, the values of the sample number were set at 500, 1000, 2000, 4000, and 8000. It will take a couple of minutes to run <code>sample_converge()</code></p>
<pre class="r"><code>sample &lt;- c(500, 1000, 2000, 4000, 8000)
set.seed(88771)
system.time(converge_list &lt;- sample_converge(sample, param(mod), TVCL:TVVP))</code></pre>
<pre class="r"><code>df &lt;- do.call(rbind, list(converge_list[[1]] %&gt;% melt() %&gt;% cbind(type = &quot;MC&quot;),
                          converge_list[[2]] %&gt;% melt() %&gt;% cbind(type = &quot;log_MC&quot;),
                          converge_list[[3]] %&gt;% melt() %&gt;% cbind(type = &quot;log_QMC&quot;)))</code></pre>
<p>Finally, visualizing the result to see the convergence of each parameter. Both QMC and MC random sampling showed a similar result. Each parameter was close or below the threshold of 0.05. However, it’s hard to conclude that the QMC can provide the best way for Sobol sensitivity analysis in pharmacokinetic modeling.</p>
<pre class="r"><code>theme_set(theme_light())
df %&gt;% `colnames&lt;-`(c(&quot;sample.no&quot;, &quot;parameter&quot;, &quot;index&quot;, &quot;type&quot;)) %&gt;%
  ggplot(aes(sample.no, index, group = parameter)) + 
  geom_line(aes(color = parameter)) + 
  facet_wrap(~type) + 
  expand_limits(y= c(0, 0.5)) + 
  geom_hline(yintercept = 0.05, linetype=&quot;dashed&quot;, size = 0.2) +
  labs(y = &quot;Convergence index&quot;, x = &quot;Sample number&quot;) +
  theme(legend.position = &quot;top&quot;)</code></pre>
</div>
</div>
<div id="take-away" class="section level1">
<h1>Take away</h1>
<ol style="list-style-type: decimal">
<li><p>Always plot the data. Because the devil might in the detail and your data might look likes a dinosaur.</p></li>
<li><p>Rethinking about the sampling. If the sampling range is too wide, try using the log-transformed method.</p></li>
<li><p>Finally, try Quasi-Monte Carlo. The QMC method can generate distribution than random MC sampling uniformly. Unfortunately, QMC didn’t show the best result in convergence assessment in this case.</p></li>
</ol>
</div>
<div id="session-info" class="section level1">
<h1>Session info</h1>
<pre class="r"><code>sessionInfo()</code></pre>
</div>
